{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074dbad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting colorama (from click->nltk)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: regex, joblib, colorama, tqdm, click, nltk\n",
      "Successfully installed click-8.1.8 colorama-0.4.6 joblib-1.5.0 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\Supriya\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk.exe is installed in 'C:\\Users\\Supriya\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4->bs4)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Installing collected packages: typing-extensions, soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.13.4 bs4-0.0.2 soupsieve-2.7 typing-extensions-4.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk -U\n",
    "! pip install bs4 -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "744159cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Supriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Supriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Supriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Supriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Supriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Supriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc53c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "para=('''Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human (natural) languages. The ultimate goal of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both valuable and meaningful.\n",
    "\n",
    "NLP involves several tasks including text classification, sentiment analysis, machine translation, named entity recognition (NER), speech recognition, and more. NLP is widely used in applications such as chatbots, voice assistants, translation tools, and information retrieval systems. For example, when you ask your smartphone a question or search for something on Google, NLP is at play in the background to help interpret and process your query.\n",
    "\n",
    "One of the most important aspects of NLP is text preprocessing. Preprocessing involves several steps to clean and organize the text data before any analysis or modeling can be done. These steps include tokenization, stopword removal, lemmatization, and stemming. By breaking text into smaller chunks (tokens), removing irrelevant words (stopwords), and reducing words to their base forms (lemmatization or stemming), NLP systems can better understand and analyze text data.\n",
    "\n",
    "With the rise of machine learning and deep learning, NLP has seen significant advances. Pretrained models such as BERT, GPT, and T5 are used to perform tasks like text classification, question answering, and summarization with impressive accuracy. These models are trained on vast amounts of text data, learning patterns in language that allow them to generate human-like text and answer questions with contextually relevant responses.\n",
    "\n",
    "Despite these advancements, NLP still faces challenges. Ambiguity, cultural context, idiomatic expressions, and domain-specific language can all make it difficult for computers to fully understand human language. However, ongoing research and innovations in the field continue to push the boundaries of what is possible with NLP and AI in general.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5396a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human (natural) languages. The ultimate goal of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both valuable and meaningful.\n",
      "\n",
      "NLP involves several tasks including text classification, sentiment analysis, machine translation, named entity recognition (NER), speech recognition, and more. NLP is widely used in applications such as chatbots, voice assistants, translation tools, and information retrieval systems. For example, when you ask your smartphone a question or search for something on Google, NLP is at play in the background to help interpret and process your query.\n",
      "\n",
      "One of the most important aspects of NLP is text preprocessing. Preprocessing involves several steps to clean and organize the text data before any analysis or modeling can be done. These steps include tokenization, stopword removal, lemmatization, and stemming. By breaking text into smaller chunks (tokens), removing irrelevant words (stopwords), and reducing words to their base forms (lemmatization or stemming), NLP systems can better understand and analyze text data.\n",
      "\n",
      "With the rise of machine learning and deep learning, NLP has seen significant advances. Pretrained models such as BERT, GPT, and T5 are used to perform tasks like text classification, question answering, and summarization with impressive accuracy. These models are trained on vast amounts of text data, learning patterns in language that allow them to generate human-like text and answer questions with contextually relevant responses.\n",
      "\n",
      "Despite these advancements, NLP still faces challenges. Ambiguity, cultural context, idiomatic expressions, and domain-specific language can all make it difficult for computers to fully understand human language. However, ongoing research and innovations in the field continue to push the boundaries of what is possible with NLP and AI in general.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67822454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(NLP)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'that',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'the',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " '(natural)',\n",
       " 'languages.',\n",
       " 'The',\n",
       " 'ultimate',\n",
       " 'goal',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand,',\n",
       " 'interpret,',\n",
       " 'and',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'languages',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'that',\n",
       " 'is',\n",
       " 'both',\n",
       " 'valuable',\n",
       " 'and',\n",
       " 'meaningful.',\n",
       " 'NLP',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'tasks',\n",
       " 'including',\n",
       " 'text',\n",
       " 'classification,',\n",
       " 'sentiment',\n",
       " 'analysis,',\n",
       " 'machine',\n",
       " 'translation,',\n",
       " 'named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " '(NER),',\n",
       " 'speech',\n",
       " 'recognition,',\n",
       " 'and',\n",
       " 'more.',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'in',\n",
       " 'applications',\n",
       " 'such',\n",
       " 'as',\n",
       " 'chatbots,',\n",
       " 'voice',\n",
       " 'assistants,',\n",
       " 'translation',\n",
       " 'tools,',\n",
       " 'and',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " 'systems.',\n",
       " 'For',\n",
       " 'example,',\n",
       " 'when',\n",
       " 'you',\n",
       " 'ask',\n",
       " 'your',\n",
       " 'smartphone',\n",
       " 'a',\n",
       " 'question',\n",
       " 'or',\n",
       " 'search',\n",
       " 'for',\n",
       " 'something',\n",
       " 'on',\n",
       " 'Google,',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'at',\n",
       " 'play',\n",
       " 'in',\n",
       " 'the',\n",
       " 'background',\n",
       " 'to',\n",
       " 'help',\n",
       " 'interpret',\n",
       " 'and',\n",
       " 'process',\n",
       " 'your',\n",
       " 'query.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'important',\n",
       " 'aspects',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'text',\n",
       " 'preprocessing.',\n",
       " 'Preprocessing',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'steps',\n",
       " 'to',\n",
       " 'clean',\n",
       " 'and',\n",
       " 'organize',\n",
       " 'the',\n",
       " 'text',\n",
       " 'data',\n",
       " 'before',\n",
       " 'any',\n",
       " 'analysis',\n",
       " 'or',\n",
       " 'modeling',\n",
       " 'can',\n",
       " 'be',\n",
       " 'done.',\n",
       " 'These',\n",
       " 'steps',\n",
       " 'include',\n",
       " 'tokenization,',\n",
       " 'stopword',\n",
       " 'removal,',\n",
       " 'lemmatization,',\n",
       " 'and',\n",
       " 'stemming.',\n",
       " 'By',\n",
       " 'breaking',\n",
       " 'text',\n",
       " 'into',\n",
       " 'smaller',\n",
       " 'chunks',\n",
       " '(tokens),',\n",
       " 'removing',\n",
       " 'irrelevant',\n",
       " 'words',\n",
       " '(stopwords),',\n",
       " 'and',\n",
       " 'reducing',\n",
       " 'words',\n",
       " 'to',\n",
       " 'their',\n",
       " 'base',\n",
       " 'forms',\n",
       " '(lemmatization',\n",
       " 'or',\n",
       " 'stemming),',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " 'can',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'data.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rise',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'deep',\n",
       " 'learning,',\n",
       " 'NLP',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'significant',\n",
       " 'advances.',\n",
       " 'Pretrained',\n",
       " 'models',\n",
       " 'such',\n",
       " 'as',\n",
       " 'BERT,',\n",
       " 'GPT,',\n",
       " 'and',\n",
       " 'T5',\n",
       " 'are',\n",
       " 'used',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'tasks',\n",
       " 'like',\n",
       " 'text',\n",
       " 'classification,',\n",
       " 'question',\n",
       " 'answering,',\n",
       " 'and',\n",
       " 'summarization',\n",
       " 'with',\n",
       " 'impressive',\n",
       " 'accuracy.',\n",
       " 'These',\n",
       " 'models',\n",
       " 'are',\n",
       " 'trained',\n",
       " 'on',\n",
       " 'vast',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'text',\n",
       " 'data,',\n",
       " 'learning',\n",
       " 'patterns',\n",
       " 'in',\n",
       " 'language',\n",
       " 'that',\n",
       " 'allow',\n",
       " 'them',\n",
       " 'to',\n",
       " 'generate',\n",
       " 'human-like',\n",
       " 'text',\n",
       " 'and',\n",
       " 'answer',\n",
       " 'questions',\n",
       " 'with',\n",
       " 'contextually',\n",
       " 'relevant',\n",
       " 'responses.',\n",
       " 'Despite',\n",
       " 'these',\n",
       " 'advancements,',\n",
       " 'NLP',\n",
       " 'still',\n",
       " 'faces',\n",
       " 'challenges.',\n",
       " 'Ambiguity,',\n",
       " 'cultural',\n",
       " 'context,',\n",
       " 'idiomatic',\n",
       " 'expressions,',\n",
       " 'and',\n",
       " 'domain-specific',\n",
       " 'language',\n",
       " 'can',\n",
       " 'all',\n",
       " 'make',\n",
       " 'it',\n",
       " 'difficult',\n",
       " 'for',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'fully',\n",
       " 'understand',\n",
       " 'human',\n",
       " 'language.',\n",
       " 'However,',\n",
       " 'ongoing',\n",
       " 'research',\n",
       " 'and',\n",
       " 'innovations',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'push',\n",
       " 'the',\n",
       " 'boundaries',\n",
       " 'of',\n",
       " 'what',\n",
       " 'is',\n",
       " 'possible',\n",
       " 'with',\n",
       " 'NLP',\n",
       " 'and',\n",
       " 'AI',\n",
       " 'in',\n",
       " 'general.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dbd02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec6552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "565d4ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP involves several tasks including text classification, sentiment analysis, machine translation, named entity recognition (NER), speech recognition, and more.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff80426",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=word_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d44e6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'that',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'the',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " '(',\n",
       " 'natural',\n",
       " ')',\n",
       " 'languages',\n",
       " '.',\n",
       " 'The',\n",
       " 'ultimate',\n",
       " 'goal',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " ',',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'and',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'languages',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'that',\n",
       " 'is',\n",
       " 'both',\n",
       " 'valuable',\n",
       " 'and',\n",
       " 'meaningful',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'tasks',\n",
       " 'including',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " 'named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " '(',\n",
       " 'NER',\n",
       " ')',\n",
       " ',',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'in',\n",
       " 'applications',\n",
       " 'such',\n",
       " 'as',\n",
       " 'chatbots',\n",
       " ',',\n",
       " 'voice',\n",
       " 'assistants',\n",
       " ',',\n",
       " 'translation',\n",
       " 'tools',\n",
       " ',',\n",
       " 'and',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " 'systems',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " ',',\n",
       " 'when',\n",
       " 'you',\n",
       " 'ask',\n",
       " 'your',\n",
       " 'smartphone',\n",
       " 'a',\n",
       " 'question',\n",
       " 'or',\n",
       " 'search',\n",
       " 'for',\n",
       " 'something',\n",
       " 'on',\n",
       " 'Google',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'at',\n",
       " 'play',\n",
       " 'in',\n",
       " 'the',\n",
       " 'background',\n",
       " 'to',\n",
       " 'help',\n",
       " 'interpret',\n",
       " 'and',\n",
       " 'process',\n",
       " 'your',\n",
       " 'query',\n",
       " '.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'important',\n",
       " 'aspects',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'text',\n",
       " 'preprocessing',\n",
       " '.',\n",
       " 'Preprocessing',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'steps',\n",
       " 'to',\n",
       " 'clean',\n",
       " 'and',\n",
       " 'organize',\n",
       " 'the',\n",
       " 'text',\n",
       " 'data',\n",
       " 'before',\n",
       " 'any',\n",
       " 'analysis',\n",
       " 'or',\n",
       " 'modeling',\n",
       " 'can',\n",
       " 'be',\n",
       " 'done',\n",
       " '.',\n",
       " 'These',\n",
       " 'steps',\n",
       " 'include',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stopword',\n",
       " 'removal',\n",
       " ',',\n",
       " 'lemmatization',\n",
       " ',',\n",
       " 'and',\n",
       " 'stemming',\n",
       " '.',\n",
       " 'By',\n",
       " 'breaking',\n",
       " 'text',\n",
       " 'into',\n",
       " 'smaller',\n",
       " 'chunks',\n",
       " '(',\n",
       " 'tokens',\n",
       " ')',\n",
       " ',',\n",
       " 'removing',\n",
       " 'irrelevant',\n",
       " 'words',\n",
       " '(',\n",
       " 'stopwords',\n",
       " ')',\n",
       " ',',\n",
       " 'and',\n",
       " 'reducing',\n",
       " 'words',\n",
       " 'to',\n",
       " 'their',\n",
       " 'base',\n",
       " 'forms',\n",
       " '(',\n",
       " 'lemmatization',\n",
       " 'or',\n",
       " 'stemming',\n",
       " ')',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " 'can',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'data',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rise',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'significant',\n",
       " 'advances',\n",
       " '.',\n",
       " 'Pretrained',\n",
       " 'models',\n",
       " 'such',\n",
       " 'as',\n",
       " 'BERT',\n",
       " ',',\n",
       " 'GPT',\n",
       " ',',\n",
       " 'and',\n",
       " 'T5',\n",
       " 'are',\n",
       " 'used',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'tasks',\n",
       " 'like',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'question',\n",
       " 'answering',\n",
       " ',',\n",
       " 'and',\n",
       " 'summarization',\n",
       " 'with',\n",
       " 'impressive',\n",
       " 'accuracy',\n",
       " '.',\n",
       " 'These',\n",
       " 'models',\n",
       " 'are',\n",
       " 'trained',\n",
       " 'on',\n",
       " 'vast',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'text',\n",
       " 'data',\n",
       " ',',\n",
       " 'learning',\n",
       " 'patterns',\n",
       " 'in',\n",
       " 'language',\n",
       " 'that',\n",
       " 'allow',\n",
       " 'them',\n",
       " 'to',\n",
       " 'generate',\n",
       " 'human-like',\n",
       " 'text',\n",
       " 'and',\n",
       " 'answer',\n",
       " 'questions',\n",
       " 'with',\n",
       " 'contextually',\n",
       " 'relevant',\n",
       " 'responses',\n",
       " '.',\n",
       " 'Despite',\n",
       " 'these',\n",
       " 'advancements',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'still',\n",
       " 'faces',\n",
       " 'challenges',\n",
       " '.',\n",
       " 'Ambiguity',\n",
       " ',',\n",
       " 'cultural',\n",
       " 'context',\n",
       " ',',\n",
       " 'idiomatic',\n",
       " 'expressions',\n",
       " ',',\n",
       " 'and',\n",
       " 'domain-specific',\n",
       " 'language',\n",
       " 'can',\n",
       " 'all',\n",
       " 'make',\n",
       " 'it',\n",
       " 'difficult',\n",
       " 'for',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'fully',\n",
       " 'understand',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'ongoing',\n",
       " 'research',\n",
       " 'and',\n",
       " 'innovations',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'push',\n",
       " 'the',\n",
       " 'boundaries',\n",
       " 'of',\n",
       " 'what',\n",
       " 'is',\n",
       " 'possible',\n",
       " 'with',\n",
       " 'NLP',\n",
       " 'and',\n",
       " 'AI',\n",
       " 'in',\n",
       " 'general',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fb77e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b23a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "swords=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3d9dc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "426a7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[word for word in words if word not in swords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ff03d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'field',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'focuses',\n",
       " 'interaction',\n",
       " 'computers',\n",
       " 'human',\n",
       " '(',\n",
       " 'natural',\n",
       " ')',\n",
       " 'languages',\n",
       " '.',\n",
       " 'The',\n",
       " 'ultimate',\n",
       " 'goal',\n",
       " 'NLP',\n",
       " 'enable',\n",
       " 'computers',\n",
       " 'understand',\n",
       " ',',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'languages',\n",
       " 'way',\n",
       " 'valuable',\n",
       " 'meaningful',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'tasks',\n",
       " 'including',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " 'named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " '(',\n",
       " 'NER',\n",
       " ')',\n",
       " ',',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " ',',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'applications',\n",
       " 'chatbots',\n",
       " ',',\n",
       " 'voice',\n",
       " 'assistants',\n",
       " ',',\n",
       " 'translation',\n",
       " 'tools',\n",
       " ',',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " 'systems',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " ',',\n",
       " 'ask',\n",
       " 'smartphone',\n",
       " 'question',\n",
       " 'search',\n",
       " 'something',\n",
       " 'Google',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'play',\n",
       " 'background',\n",
       " 'help',\n",
       " 'interpret',\n",
       " 'process',\n",
       " 'query',\n",
       " '.',\n",
       " 'One',\n",
       " 'important',\n",
       " 'aspects',\n",
       " 'NLP',\n",
       " 'text',\n",
       " 'preprocessing',\n",
       " '.',\n",
       " 'Preprocessing',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'steps',\n",
       " 'clean',\n",
       " 'organize',\n",
       " 'text',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'modeling',\n",
       " 'done',\n",
       " '.',\n",
       " 'These',\n",
       " 'steps',\n",
       " 'include',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stopword',\n",
       " 'removal',\n",
       " ',',\n",
       " 'lemmatization',\n",
       " ',',\n",
       " 'stemming',\n",
       " '.',\n",
       " 'By',\n",
       " 'breaking',\n",
       " 'text',\n",
       " 'smaller',\n",
       " 'chunks',\n",
       " '(',\n",
       " 'tokens',\n",
       " ')',\n",
       " ',',\n",
       " 'removing',\n",
       " 'irrelevant',\n",
       " 'words',\n",
       " '(',\n",
       " 'stopwords',\n",
       " ')',\n",
       " ',',\n",
       " 'reducing',\n",
       " 'words',\n",
       " 'base',\n",
       " 'forms',\n",
       " '(',\n",
       " 'lemmatization',\n",
       " 'stemming',\n",
       " ')',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'data',\n",
       " '.',\n",
       " 'With',\n",
       " 'rise',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'seen',\n",
       " 'significant',\n",
       " 'advances',\n",
       " '.',\n",
       " 'Pretrained',\n",
       " 'models',\n",
       " 'BERT',\n",
       " ',',\n",
       " 'GPT',\n",
       " ',',\n",
       " 'T5',\n",
       " 'used',\n",
       " 'perform',\n",
       " 'tasks',\n",
       " 'like',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'question',\n",
       " 'answering',\n",
       " ',',\n",
       " 'summarization',\n",
       " 'impressive',\n",
       " 'accuracy',\n",
       " '.',\n",
       " 'These',\n",
       " 'models',\n",
       " 'trained',\n",
       " 'vast',\n",
       " 'amounts',\n",
       " 'text',\n",
       " 'data',\n",
       " ',',\n",
       " 'learning',\n",
       " 'patterns',\n",
       " 'language',\n",
       " 'allow',\n",
       " 'generate',\n",
       " 'human-like',\n",
       " 'text',\n",
       " 'answer',\n",
       " 'questions',\n",
       " 'contextually',\n",
       " 'relevant',\n",
       " 'responses',\n",
       " '.',\n",
       " 'Despite',\n",
       " 'advancements',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'still',\n",
       " 'faces',\n",
       " 'challenges',\n",
       " '.',\n",
       " 'Ambiguity',\n",
       " ',',\n",
       " 'cultural',\n",
       " 'context',\n",
       " ',',\n",
       " 'idiomatic',\n",
       " 'expressions',\n",
       " ',',\n",
       " 'domain-specific',\n",
       " 'language',\n",
       " 'make',\n",
       " 'difficult',\n",
       " 'computers',\n",
       " 'fully',\n",
       " 'understand',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'ongoing',\n",
       " 'research',\n",
       " 'innovations',\n",
       " 'field',\n",
       " 'continue',\n",
       " 'push',\n",
       " 'boundaries',\n",
       " 'possible',\n",
       " 'NLP',\n",
       " 'AI',\n",
       " 'general',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15d80a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368c94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e119e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78bb9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[ps.stem(word) for word in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17b079d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " '(',\n",
       " 'nlp',\n",
       " ')',\n",
       " 'field',\n",
       " 'artifici',\n",
       " 'intellig',\n",
       " 'focus',\n",
       " 'interact',\n",
       " 'comput',\n",
       " 'human',\n",
       " '(',\n",
       " 'natur',\n",
       " ')',\n",
       " 'languag',\n",
       " '.',\n",
       " 'the',\n",
       " 'ultim',\n",
       " 'goal',\n",
       " 'nlp',\n",
       " 'enabl',\n",
       " 'comput',\n",
       " 'understand',\n",
       " ',',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'gener',\n",
       " 'human',\n",
       " 'languag',\n",
       " 'way',\n",
       " 'valuabl',\n",
       " 'meaning',\n",
       " '.',\n",
       " 'nlp',\n",
       " 'involv',\n",
       " 'sever',\n",
       " 'task',\n",
       " 'includ',\n",
       " 'text',\n",
       " 'classif',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysi',\n",
       " ',',\n",
       " 'machin',\n",
       " 'translat',\n",
       " ',',\n",
       " 'name',\n",
       " 'entiti',\n",
       " 'recognit',\n",
       " '(',\n",
       " 'ner',\n",
       " ')',\n",
       " ',',\n",
       " 'speech',\n",
       " 'recognit',\n",
       " ',',\n",
       " '.',\n",
       " 'nlp',\n",
       " 'wide',\n",
       " 'use',\n",
       " 'applic',\n",
       " 'chatbot',\n",
       " ',',\n",
       " 'voic',\n",
       " 'assist',\n",
       " ',',\n",
       " 'translat',\n",
       " 'tool',\n",
       " ',',\n",
       " 'inform',\n",
       " 'retriev',\n",
       " 'system',\n",
       " '.',\n",
       " 'for',\n",
       " 'exampl',\n",
       " ',',\n",
       " 'ask',\n",
       " 'smartphon',\n",
       " 'question',\n",
       " 'search',\n",
       " 'someth',\n",
       " 'googl',\n",
       " ',',\n",
       " 'nlp',\n",
       " 'play',\n",
       " 'background',\n",
       " 'help',\n",
       " 'interpret',\n",
       " 'process',\n",
       " 'queri',\n",
       " '.',\n",
       " 'one',\n",
       " 'import',\n",
       " 'aspect',\n",
       " 'nlp',\n",
       " 'text',\n",
       " 'preprocess',\n",
       " '.',\n",
       " 'preprocess',\n",
       " 'involv',\n",
       " 'sever',\n",
       " 'step',\n",
       " 'clean',\n",
       " 'organ',\n",
       " 'text',\n",
       " 'data',\n",
       " 'analysi',\n",
       " 'model',\n",
       " 'done',\n",
       " '.',\n",
       " 'these',\n",
       " 'step',\n",
       " 'includ',\n",
       " 'token',\n",
       " ',',\n",
       " 'stopword',\n",
       " 'remov',\n",
       " ',',\n",
       " 'lemmat',\n",
       " ',',\n",
       " 'stem',\n",
       " '.',\n",
       " 'by',\n",
       " 'break',\n",
       " 'text',\n",
       " 'smaller',\n",
       " 'chunk',\n",
       " '(',\n",
       " 'token',\n",
       " ')',\n",
       " ',',\n",
       " 'remov',\n",
       " 'irrelev',\n",
       " 'word',\n",
       " '(',\n",
       " 'stopword',\n",
       " ')',\n",
       " ',',\n",
       " 'reduc',\n",
       " 'word',\n",
       " 'base',\n",
       " 'form',\n",
       " '(',\n",
       " 'lemmat',\n",
       " 'stem',\n",
       " ')',\n",
       " ',',\n",
       " 'nlp',\n",
       " 'system',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'analyz',\n",
       " 'text',\n",
       " 'data',\n",
       " '.',\n",
       " 'with',\n",
       " 'rise',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'deep',\n",
       " 'learn',\n",
       " ',',\n",
       " 'nlp',\n",
       " 'seen',\n",
       " 'signific',\n",
       " 'advanc',\n",
       " '.',\n",
       " 'pretrain',\n",
       " 'model',\n",
       " 'bert',\n",
       " ',',\n",
       " 'gpt',\n",
       " ',',\n",
       " 't5',\n",
       " 'use',\n",
       " 'perform',\n",
       " 'task',\n",
       " 'like',\n",
       " 'text',\n",
       " 'classif',\n",
       " ',',\n",
       " 'question',\n",
       " 'answer',\n",
       " ',',\n",
       " 'summar',\n",
       " 'impress',\n",
       " 'accuraci',\n",
       " '.',\n",
       " 'these',\n",
       " 'model',\n",
       " 'train',\n",
       " 'vast',\n",
       " 'amount',\n",
       " 'text',\n",
       " 'data',\n",
       " ',',\n",
       " 'learn',\n",
       " 'pattern',\n",
       " 'languag',\n",
       " 'allow',\n",
       " 'gener',\n",
       " 'human-lik',\n",
       " 'text',\n",
       " 'answer',\n",
       " 'question',\n",
       " 'contextu',\n",
       " 'relev',\n",
       " 'respons',\n",
       " '.',\n",
       " 'despit',\n",
       " 'advanc',\n",
       " ',',\n",
       " 'nlp',\n",
       " 'still',\n",
       " 'face',\n",
       " 'challeng',\n",
       " '.',\n",
       " 'ambigu',\n",
       " ',',\n",
       " 'cultur',\n",
       " 'context',\n",
       " ',',\n",
       " 'idiomat',\n",
       " 'express',\n",
       " ',',\n",
       " 'domain-specif',\n",
       " 'languag',\n",
       " 'make',\n",
       " 'difficult',\n",
       " 'comput',\n",
       " 'fulli',\n",
       " 'understand',\n",
       " 'human',\n",
       " 'languag',\n",
       " '.',\n",
       " 'howev',\n",
       " ',',\n",
       " 'ongo',\n",
       " 'research',\n",
       " 'innov',\n",
       " 'field',\n",
       " 'continu',\n",
       " 'push',\n",
       " 'boundari',\n",
       " 'possibl',\n",
       " 'nlp',\n",
       " 'ai',\n",
       " 'gener',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ca1af0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Supriya\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17cc8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6b47c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn1=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ecdccd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn1.lemmatize('working',pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1034b80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('went'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5868018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "print (wn1.lemmatize('went',pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "483672b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=[wn1.lemmatize(word,pos='v') for word in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bfaa722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'process',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'field',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'focus',\n",
       " 'interaction',\n",
       " 'computers',\n",
       " 'human',\n",
       " '(',\n",
       " 'natural',\n",
       " ')',\n",
       " 'languages',\n",
       " '.',\n",
       " 'The',\n",
       " 'ultimate',\n",
       " 'goal',\n",
       " 'NLP',\n",
       " 'enable',\n",
       " 'computers',\n",
       " 'understand',\n",
       " ',',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'languages',\n",
       " 'way',\n",
       " 'valuable',\n",
       " 'meaningful',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'involve',\n",
       " 'several',\n",
       " 'task',\n",
       " 'include',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " 'name',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " '(',\n",
       " 'NER',\n",
       " ')',\n",
       " ',',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " ',',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'widely',\n",
       " 'use',\n",
       " 'applications',\n",
       " 'chatbots',\n",
       " ',',\n",
       " 'voice',\n",
       " 'assistants',\n",
       " ',',\n",
       " 'translation',\n",
       " 'tool',\n",
       " ',',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " 'systems',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " ',',\n",
       " 'ask',\n",
       " 'smartphone',\n",
       " 'question',\n",
       " 'search',\n",
       " 'something',\n",
       " 'Google',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'play',\n",
       " 'background',\n",
       " 'help',\n",
       " 'interpret',\n",
       " 'process',\n",
       " 'query',\n",
       " '.',\n",
       " 'One',\n",
       " 'important',\n",
       " 'aspects',\n",
       " 'NLP',\n",
       " 'text',\n",
       " 'preprocessing',\n",
       " '.',\n",
       " 'Preprocessing',\n",
       " 'involve',\n",
       " 'several',\n",
       " 'step',\n",
       " 'clean',\n",
       " 'organize',\n",
       " 'text',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'model',\n",
       " 'do',\n",
       " '.',\n",
       " 'These',\n",
       " 'step',\n",
       " 'include',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stopword',\n",
       " 'removal',\n",
       " ',',\n",
       " 'lemmatization',\n",
       " ',',\n",
       " 'stem',\n",
       " '.',\n",
       " 'By',\n",
       " 'break',\n",
       " 'text',\n",
       " 'smaller',\n",
       " 'chunk',\n",
       " '(',\n",
       " 'tokens',\n",
       " ')',\n",
       " ',',\n",
       " 'remove',\n",
       " 'irrelevant',\n",
       " 'word',\n",
       " '(',\n",
       " 'stopwords',\n",
       " ')',\n",
       " ',',\n",
       " 'reduce',\n",
       " 'word',\n",
       " 'base',\n",
       " 'form',\n",
       " '(',\n",
       " 'lemmatization',\n",
       " 'stem',\n",
       " ')',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'data',\n",
       " '.',\n",
       " 'With',\n",
       " 'rise',\n",
       " 'machine',\n",
       " 'learn',\n",
       " 'deep',\n",
       " 'learn',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'see',\n",
       " 'significant',\n",
       " 'advance',\n",
       " '.',\n",
       " 'Pretrained',\n",
       " 'model',\n",
       " 'BERT',\n",
       " ',',\n",
       " 'GPT',\n",
       " ',',\n",
       " 'T5',\n",
       " 'use',\n",
       " 'perform',\n",
       " 'task',\n",
       " 'like',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'question',\n",
       " 'answer',\n",
       " ',',\n",
       " 'summarization',\n",
       " 'impressive',\n",
       " 'accuracy',\n",
       " '.',\n",
       " 'These',\n",
       " 'model',\n",
       " 'train',\n",
       " 'vast',\n",
       " 'amount',\n",
       " 'text',\n",
       " 'data',\n",
       " ',',\n",
       " 'learn',\n",
       " 'pattern',\n",
       " 'language',\n",
       " 'allow',\n",
       " 'generate',\n",
       " 'human-like',\n",
       " 'text',\n",
       " 'answer',\n",
       " 'question',\n",
       " 'contextually',\n",
       " 'relevant',\n",
       " 'responses',\n",
       " '.',\n",
       " 'Despite',\n",
       " 'advancements',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'still',\n",
       " 'face',\n",
       " 'challenge',\n",
       " '.',\n",
       " 'Ambiguity',\n",
       " ',',\n",
       " 'cultural',\n",
       " 'context',\n",
       " ',',\n",
       " 'idiomatic',\n",
       " 'expressions',\n",
       " ',',\n",
       " 'domain-specific',\n",
       " 'language',\n",
       " 'make',\n",
       " 'difficult',\n",
       " 'computers',\n",
       " 'fully',\n",
       " 'understand',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'ongoing',\n",
       " 'research',\n",
       " 'innovations',\n",
       " 'field',\n",
       " 'continue',\n",
       " 'push',\n",
       " 'boundaries',\n",
       " 'possible',\n",
       " 'NLP',\n",
       " 'AI',\n",
       " 'general',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63629592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da2262f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d915fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[word for word in words if word not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4f5e302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'that',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'the',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'natural',\n",
       " 'languages',\n",
       " 'The',\n",
       " 'ultimate',\n",
       " 'goal',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'and',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'languages',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'that',\n",
       " 'is',\n",
       " 'both',\n",
       " 'valuable',\n",
       " 'and',\n",
       " 'meaningful',\n",
       " 'NLP',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'tasks',\n",
       " 'including',\n",
       " 'text',\n",
       " 'classification',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " 'NER',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " 'and',\n",
       " 'more',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'in',\n",
       " 'applications',\n",
       " 'such',\n",
       " 'as',\n",
       " 'chatbots',\n",
       " 'voice',\n",
       " 'assistants',\n",
       " 'translation',\n",
       " 'tools',\n",
       " 'and',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " 'systems',\n",
       " 'For',\n",
       " 'example',\n",
       " 'when',\n",
       " 'you',\n",
       " 'ask',\n",
       " 'your',\n",
       " 'smartphone',\n",
       " 'a',\n",
       " 'question',\n",
       " 'or',\n",
       " 'search',\n",
       " 'for',\n",
       " 'something',\n",
       " 'on',\n",
       " 'Google',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'at',\n",
       " 'play',\n",
       " 'in',\n",
       " 'the',\n",
       " 'background',\n",
       " 'to',\n",
       " 'help',\n",
       " 'interpret',\n",
       " 'and',\n",
       " 'process',\n",
       " 'your',\n",
       " 'query',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'important',\n",
       " 'aspects',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'text',\n",
       " 'preprocessing',\n",
       " 'Preprocessing',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'steps',\n",
       " 'to',\n",
       " 'clean',\n",
       " 'and',\n",
       " 'organize',\n",
       " 'the',\n",
       " 'text',\n",
       " 'data',\n",
       " 'before',\n",
       " 'any',\n",
       " 'analysis',\n",
       " 'or',\n",
       " 'modeling',\n",
       " 'can',\n",
       " 'be',\n",
       " 'done',\n",
       " 'These',\n",
       " 'steps',\n",
       " 'include',\n",
       " 'tokenization',\n",
       " 'stopword',\n",
       " 'removal',\n",
       " 'lemmatization',\n",
       " 'and',\n",
       " 'stemming',\n",
       " 'By',\n",
       " 'breaking',\n",
       " 'text',\n",
       " 'into',\n",
       " 'smaller',\n",
       " 'chunks',\n",
       " 'tokens',\n",
       " 'removing',\n",
       " 'irrelevant',\n",
       " 'words',\n",
       " 'stopwords',\n",
       " 'and',\n",
       " 'reducing',\n",
       " 'words',\n",
       " 'to',\n",
       " 'their',\n",
       " 'base',\n",
       " 'forms',\n",
       " 'lemmatization',\n",
       " 'or',\n",
       " 'stemming',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " 'can',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'data',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rise',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'NLP',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'significant',\n",
       " 'advances',\n",
       " 'Pretrained',\n",
       " 'models',\n",
       " 'such',\n",
       " 'as',\n",
       " 'BERT',\n",
       " 'GPT',\n",
       " 'and',\n",
       " 'T5',\n",
       " 'are',\n",
       " 'used',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'tasks',\n",
       " 'like',\n",
       " 'text',\n",
       " 'classification',\n",
       " 'question',\n",
       " 'answering',\n",
       " 'and',\n",
       " 'summarization',\n",
       " 'with',\n",
       " 'impressive',\n",
       " 'accuracy',\n",
       " 'These',\n",
       " 'models',\n",
       " 'are',\n",
       " 'trained',\n",
       " 'on',\n",
       " 'vast',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'text',\n",
       " 'data',\n",
       " 'learning',\n",
       " 'patterns',\n",
       " 'in',\n",
       " 'language',\n",
       " 'that',\n",
       " 'allow',\n",
       " 'them',\n",
       " 'to',\n",
       " 'generate',\n",
       " 'human-like',\n",
       " 'text',\n",
       " 'and',\n",
       " 'answer',\n",
       " 'questions',\n",
       " 'with',\n",
       " 'contextually',\n",
       " 'relevant',\n",
       " 'responses',\n",
       " 'Despite',\n",
       " 'these',\n",
       " 'advancements',\n",
       " 'NLP',\n",
       " 'still',\n",
       " 'faces',\n",
       " 'challenges',\n",
       " 'Ambiguity',\n",
       " 'cultural',\n",
       " 'context',\n",
       " 'idiomatic',\n",
       " 'expressions',\n",
       " 'and',\n",
       " 'domain-specific',\n",
       " 'language',\n",
       " 'can',\n",
       " 'all',\n",
       " 'make',\n",
       " 'it',\n",
       " 'difficult',\n",
       " 'for',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'fully',\n",
       " 'understand',\n",
       " 'human',\n",
       " 'language',\n",
       " 'However',\n",
       " 'ongoing',\n",
       " 'research',\n",
       " 'and',\n",
       " 'innovations',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'push',\n",
       " 'the',\n",
       " 'boundaries',\n",
       " 'of',\n",
       " 'what',\n",
       " 'is',\n",
       " 'possible',\n",
       " 'with',\n",
       " 'NLP',\n",
       " 'and',\n",
       " 'AI',\n",
       " 'in',\n",
       " 'general']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c9d6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d552aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('NLP', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('field', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('artificial', 'JJ'),\n",
       " ('intelligence', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('focuses', 'VBZ'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('interaction', 'NN'),\n",
       " ('between', 'IN'),\n",
       " ('computers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('human', 'JJ'),\n",
       " ('natural', 'JJ'),\n",
       " ('languages', 'VBZ'),\n",
       " ('The', 'DT'),\n",
       " ('ultimate', 'JJ'),\n",
       " ('goal', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('NLP', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('enable', 'JJ'),\n",
       " ('computers', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('understand', 'VB'),\n",
       " ('interpret', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('generate', 'NN'),\n",
       " ('human', 'JJ'),\n",
       " ('languages', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('both', 'DT'),\n",
       " ('valuable', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('meaningful', 'JJ'),\n",
       " ('NLP', 'NNP'),\n",
       " ('involves', 'VBZ'),\n",
       " ('several', 'JJ'),\n",
       " ('tasks', 'NNS'),\n",
       " ('including', 'VBG'),\n",
       " ('text', 'JJ'),\n",
       " ('classification', 'NN'),\n",
       " ('sentiment', 'NN'),\n",
       " ('analysis', 'NN'),\n",
       " ('machine', 'NN'),\n",
       " ('translation', 'NN'),\n",
       " ('named', 'VBN'),\n",
       " ('entity', 'NN'),\n",
       " ('recognition', 'NN'),\n",
       " ('NER', 'NNP'),\n",
       " ('speech', 'NN'),\n",
       " ('recognition', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('more', 'JJR'),\n",
       " ('NLP', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('widely', 'RB'),\n",
       " ('used', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('applications', 'NNS'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('chatbots', 'NNS'),\n",
       " ('voice', 'NN'),\n",
       " ('assistants', 'NNS'),\n",
       " ('translation', 'NN'),\n",
       " ('tools', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('information', 'NN'),\n",
       " ('retrieval', 'NN'),\n",
       " ('systems', 'NNS'),\n",
       " ('For', 'IN'),\n",
       " ('example', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('ask', 'VBP'),\n",
       " ('your', 'PRP$'),\n",
       " ('smartphone', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('question', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('search', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Google', 'NNP'),\n",
       " ('NLP', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('at', 'IN'),\n",
       " ('play', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('background', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('help', 'VB'),\n",
       " ('interpret', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('process', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('query', 'NN'),\n",
       " ('One', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('important', 'JJ'),\n",
       " ('aspects', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('NLP', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('text', 'JJ'),\n",
       " ('preprocessing', 'VBG'),\n",
       " ('Preprocessing', 'VBG'),\n",
       " ('involves', 'NNS'),\n",
       " ('several', 'JJ'),\n",
       " ('steps', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('clean', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('organize', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('text', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('before', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('analysis', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('modeling', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('done', 'VBN'),\n",
       " ('These', 'DT'),\n",
       " ('steps', 'NNS'),\n",
       " ('include', 'VBP'),\n",
       " ('tokenization', 'NN'),\n",
       " ('stopword', 'NN'),\n",
       " ('removal', 'NN'),\n",
       " ('lemmatization', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('stemming', 'NN'),\n",
       " ('By', 'IN'),\n",
       " ('breaking', 'VBG'),\n",
       " ('text', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('smaller', 'JJR'),\n",
       " ('chunks', 'NNS'),\n",
       " ('tokens', 'NNS'),\n",
       " ('removing', 'VBG'),\n",
       " ('irrelevant', 'JJ'),\n",
       " ('words', 'NNS'),\n",
       " ('stopwords', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('reducing', 'VBG'),\n",
       " ('words', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('their', 'PRP$'),\n",
       " ('base', 'NN'),\n",
       " ('forms', 'VBZ'),\n",
       " ('lemmatization', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('stemming', 'VBG'),\n",
       " ('NLP', 'JJ'),\n",
       " ('systems', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('better', 'VB'),\n",
       " ('understand', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('analyze', 'NN'),\n",
       " ('text', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('With', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('rise', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('deep', 'JJ'),\n",
       " ('learning', 'NN'),\n",
       " ('NLP', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('seen', 'VBN'),\n",
       " ('significant', 'JJ'),\n",
       " ('advances', 'NNS'),\n",
       " ('Pretrained', 'VBD'),\n",
       " ('models', 'NNS'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('BERT', 'NNP'),\n",
       " ('GPT', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('T5', 'NNP'),\n",
       " ('are', 'VBP'),\n",
       " ('used', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('perform', 'VB'),\n",
       " ('tasks', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('text', 'JJ'),\n",
       " ('classification', 'NN'),\n",
       " ('question', 'NN'),\n",
       " ('answering', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('summarization', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('impressive', 'JJ'),\n",
       " ('accuracy', 'NN'),\n",
       " ('These', 'DT'),\n",
       " ('models', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('trained', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('vast', 'JJ'),\n",
       " ('amounts', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('text', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('learning', 'VBG'),\n",
       " ('patterns', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('language', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('allow', 'VBP'),\n",
       " ('them', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('generate', 'VB'),\n",
       " ('human-like', 'JJ'),\n",
       " ('text', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('answer', 'VB'),\n",
       " ('questions', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('contextually', 'RB'),\n",
       " ('relevant', 'JJ'),\n",
       " ('responses', 'NNS'),\n",
       " ('Despite', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('advancements', 'NNS'),\n",
       " ('NLP', 'NNP'),\n",
       " ('still', 'RB'),\n",
       " ('faces', 'VBZ'),\n",
       " ('challenges', 'NNS'),\n",
       " ('Ambiguity', 'NNP'),\n",
       " ('cultural', 'JJ'),\n",
       " ('context', 'NN'),\n",
       " ('idiomatic', 'JJ'),\n",
       " ('expressions', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('domain-specific', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('all', 'DT'),\n",
       " ('make', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('difficult', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('computers', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('fully', 'RB'),\n",
       " ('understand', 'VB'),\n",
       " ('human', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('However', 'RB'),\n",
       " ('ongoing', 'JJ'),\n",
       " ('research', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('innovations', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('field', 'NN'),\n",
       " ('continue', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('push', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('boundaries', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('what', 'WP'),\n",
       " ('is', 'VBZ'),\n",
       " ('possible', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('NLP', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('AI', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('general', 'JJ')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abd69fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca2ae162",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39ea7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=tfidf.fit_transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "084cb9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 174)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac48db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcba14cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 98)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 85)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 114)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 100)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 83)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>(0, 100)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>(0, 10)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>(0, 3)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>(0, 72)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>(0, 60)\\t1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "0       (0, 98)\\t1.0\n",
       "1       (0, 85)\\t1.0\n",
       "2      (0, 114)\\t1.0\n",
       "3      (0, 100)\\t1.0\n",
       "4       (0, 83)\\t1.0\n",
       "..               ...\n",
       "290    (0, 100)\\t1.0\n",
       "291     (0, 10)\\t1.0\n",
       "292      (0, 3)\\t1.0\n",
       "293     (0, 72)\\t1.0\n",
       "294     (0, 60)\\t1.0\n",
       "\n",
       "[295 rows x 1 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a839559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
